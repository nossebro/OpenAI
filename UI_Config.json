{
	"output_file": "Settings.json",
	"DebugMode": {
		"type": "checkbox",
		"value": false,
		"label": "Debug Messages",
		"tooltip": "Enables more detailed log messages"
	},
	"StreamerName": {
		"type": "textbox",
		"value": "nossebro",
		"label": "Streamer Name",
		"tooltip": "Insert your Twitch display name."
	},
	"BotName": {
		"type": "textbox",
		"value": "bottebro",
		"label": "Bot Name",
		"tooltip": "Insert your Twitch Bot display name."
	},
	"Command": {
		"type": "textbox",
		"value": "",
		"label": "Command",
		"tooltip": "Command to talk with the bot without \"!\". Leave blank to listen to @<BotName>."
	},
	"ChatBotLevel": {
		"type": "numberbox",
		"value": 0,
		"label": "User Level needed to talk with the bot",
		"tooltip": "0. User, 1. Regular, 2. Subscriber, 3. Mods, 4. Streamer."
	},
	"ChatBotAllowlist": {
		"type": "textbox",
		"value": "nossebro",
		"label": "Allowlist",
		"tooltip": "List of Usernames separeted by \", \" who can talk with the bot."
	},
	"ChatBotCooldown": {
		"type": "numberbox",
		"value": 3,
		"label": "Cooldown",
		"tooltip": "Number of second to cooldown before accepting new message."
	},
	"OpenAIAPIToken": {
		"type": "textbox",
		"value": "",
		"label": "API Key",
		"tooltip": "",
		"group": "Open AI"
	},
	"OpenAIModel": {
		"type": "textbox",
		"value": "text-davinci-003",
		"label": "Model",
		"tooltip": "The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code.",
		"group": "Open AI"
	},
	"OpenAITemperature": {
        "type": "slider",
        "min": 0,
        "max": 1,
        "ticks": 0.01,
        "value": 0.70,
		"label": "Temperature",
		"tooltip": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
		"group": "Open AI"
	},
	"OpenAIMaxToken": {
        "type": "slider",
        "min": 1,
        "max": 4000,
        "ticks": 1,
        "value": 90,
		"label": "Maximum length",
		"tooltip": "The maximum number of tokens to generate. Requests can use up to 2048 or 4000 token shared between prompt and completion. The exact limit varies by model. (One token is roughly 4 characters for normal English text)",
		"group": "Open AI"
	},
	"OpenAITopP": {
        "type": "slider",
        "min": 0,
        "max": 1,
        "ticks": 0.01,
        "value": 1,
		"label": "Top P",
		"tooltip": "Controls diversity via nucleus sampling: 0.50 means half of all likelihood-weighted options are considered.",
		"group": "Open AI"
	},
	"OpenAIFrequencyPenalty": {
        "type": "slider",
        "min": 0,
        "max": 1,
        "ticks": 0.01,
        "value": 0,
		"label": "Frequency Penalty",
		"tooltip": "How much to penalize new tokens based on their existing frequency in the text so far. Decreases the model's likelihood to repeat the same line verbatim.",
		"group": "Open AI"
	},
	"OpenAIPresencePenalty": {
        "type": "slider",
        "min": 0,
        "max": 1,
        "ticks": 0.01,
        "value": 0,
		"label": "Presence Penalty",
		"tooltip": "How much to penalize new tokens based on whether they appear in the text so far. Increases the model's likelihood to talk about new topics.",
		"group": "Open AI"
	}
}
